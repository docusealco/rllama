# Dockerfile for building llama.cpp on Ubuntu ARM64
# Using Ubuntu 22.04 for better compatibility (glibc 2.35)
FROM ubuntu:22.04

ENV DEBIAN_FRONTEND=noninteractive

# Install required dependencies
RUN apt update && \
    apt install -y \
    build-essential \
    git \
    cmake \
    patchelf && \
    rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /workspace

# Clone llama.cpp repository (shallow clone for faster build)
RUN git clone --depth=1 https://github.com/ggml-org/llama.cpp

# Build llama.cpp with BUILD_SHARED_LIBS=ON and set RPATH for library discovery
WORKDIR /workspace/llama.cpp
RUN cmake -B build \
    -DCMAKE_BUILD_TYPE=Release \
    -DLLAMA_CURL=OFF \
    -DBUILD_SHARED_LIBS=ON \
    -DGGML_NATIVE=OFF \
    -DCMAKE_INSTALL_RPATH='$ORIGIN' \
    -DCMAKE_BUILD_WITH_INSTALL_RPATH=ON && \
    cmake --build build --config Release -j$(nproc)

# Set RPATH on all shared libraries so they can find each other
RUN find build -name "*.so*" -type f -exec patchelf --set-rpath '$ORIGIN' {} \; || true

# The built files will be in /workspace/llama.cpp/build
# We'll copy them out using docker cp command
CMD ["echo", "Build complete. Built files are in /workspace/llama.cpp/build"]
